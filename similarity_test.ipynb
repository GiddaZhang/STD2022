{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "clean = np.load('./Train/vfeat2048/0000.npy')\n",
    "noise = np.load('./vfeat2048/0000.npy')\n",
    "cleaned = np.load('./vfeat/0000.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2048) (10, 2048) (10, 512)\n"
     ]
    }
   ],
   "source": [
    "print(clean.shape, noise.shape, cleaned.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 均值、方差测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean 2 noise  mean: -3.3670542e-09 sigma2: 1.3856642e-13\n"
     ]
    }
   ],
   "source": [
    "# print('clean 2 cleaned ', 'mean:', np.mean(clean - cleaned), 'sigma2:', np.mean(np.square(clean - cleaned - np.mean(clean - cleaned))))\n",
    "print('clean 2 noise ', 'mean:', np.mean(clean - noise), 'sigma2:', np.mean(np.square(clean - noise - np.mean(clean - noise))))\n",
    "# print(np.mean(clean - cleaned))\n",
    "# print(np.mean(np.square(clean - noise - np.mean(clean - noise))))\n",
    "# print(np.mean(np.square(clean - cleaned - np.mean(clean - cleaned))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内积测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean 2 noise:  [1.        1.        1.        0.9999999 1.0000001 1.0000001 0.9999999\n",
      " 0.9999999 0.9999997 0.9999998]\n"
     ]
    }
   ],
   "source": [
    "# multi1 = np.sum(np.multiply(clean, cleaned), axis=1)\n",
    "multi2 = np.sum(np.multiply(clean, noise), axis=1)\n",
    "# print('clean 2 cleaned: ', np.divide(multi1, np.sum(np.multiply(clean, clean), axis=1)))\n",
    "print('clean 2 noise: ', np.divide(multi2, np.sum(np.multiply(clean, clean), axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=512)\n",
    "# clean = np.concatenate(clean, axis=0)\n",
    "# cleaned = np.concatenate(cleaned, axis=0)\n",
    "# noise = np.concatenate(noise, axis=0)\n",
    "new_clean = pca.fit_transform(clean)\n",
    "new_noise = pca.transform(noise)\n",
    "new_cleaned = pca.transform(cleaned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以基于以上数据暂时可以作出以下假设：\n",
    "1. 结合昨晚的结果推测助教给出的特征有点问题，而我们这边提取特征是正常的。（此条存疑，上面的分析数据都是基于`vfeat_afterpca.zip`，可能该特征本身提取得有问题）\n",
    "2. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
